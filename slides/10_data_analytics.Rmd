---
title: "Big Data Analytics"
subtitle: 'Lecture 9: Data Analytics I'
author: "Prof. Dr. Ulrich Matter"
output:
  ioslides_presentation:
    css: ../style/ioslides.css
    template: ../style/nologo_template.html
logo: ../img/logo.png
bibliography: ../references/bigdata.bib
---


```{r set-options, echo=FALSE, cache=FALSE}
options(width = 100)
library(knitr)
```

# Updates/Announcements



# Case study: Parallel processing



## Case study: Parallel processing

We start with importing the data into R.
```{r message=FALSE, warning=FALSE}
url <- "https://vincentarelbundock.github.io/Rdatasets/csv/carData/MplsStops.csv"
stopdata <- data.table::fread(url) 
```

## Case study: Parallel processing

First, let's remove observations with missing entries (`NA`) and code our main explanatory variable and the dependent variable.

```{r message=FALSE, warning=FALSE}
# remove incomplete obs
stopdata <- na.omit(stopdata)
# code dependent var
stopdata$vsearch <- 0
stopdata$vsearch[stopdata$vehicleSearch=="YES"] <- 1
# code explanatory var
stopdata$white <- 0
stopdata$white[stopdata$race=="White"] <- 1
```


## Case study: Parallel processing

We specify our baseline model as follows. 

```{r message=FALSE, warning=FALSE}
model <- vsearch ~ white + factor(policePrecinct)
```

## Case study: Parallel processing

And estimate the linear probability model via OLS (the `lm` function).

```{r message=FALSE, warning=FALSE}
fit <- lm(model, stopdata)
summary(fit)
```

## Case study: Parallel processing

Compute bootstrap clustered standard errors.

```{r message=FALSE}
# load packages
library(data.table)
# set the 'seed' for random numbers (makes the example reproducible)
set.seed(2)

# set number of bootstrap iterations
B <- 10
# get selection of precincts
precincts <- unique(stopdata$policePrecinct)
# container for coefficients
boot_coefs <- matrix(NA, nrow = B, ncol = 2)
# draw bootstrap samples, estimate model for each sample
for (i in 1:B) {
     
     # draw sample of precincts (cluster level)
     precincts_i <- sample(precincts, size = 5, replace = TRUE)
     # get observations
     bs_i <- lapply(precincts_i, function(x) stopdata[stopdata$policePrecinct==x,])
     bs_i <- rbindlist(bs_i)
     
     # estimate model and record coefficients
     boot_coefs[i,] <- coef(lm(model, bs_i))[1:2] # ignore FE-coefficients
}
```

## Case study: Parallel processing

Finally, let's compute $SE_{boot}$.

```{r message=FALSE, warning=FALSE}
se_boot <- apply(boot_coefs, 
                 MARGIN = 2,
                 FUN = sd)
se_boot
```


## Case study: Parallel processing

Parallel implementation...

```{r message=FALSE, warning=FALSE}
# install.packages("doSNOW", "parallel")
# load packages for parallel processing
library(doSNOW)
# set the 'seed' for random numbers (makes the example reproducible)
set.seed(2)

# get the number of cores available
ncores <- parallel::detectCores()
# set cores for parallel processing
ctemp <- makeCluster(ncores) # 
registerDoSNOW(ctemp)


# set number of bootstrap iterations
B <- 10
# get selection of precincts
precincts <- unique(stopdata$policePrecinct)
# container for coefficients
boot_coefs <- matrix(NA, nrow = B, ncol = 2)

# bootstrapping in parallel
boot_coefs <- 
     foreach(i = 1:B, .combine = rbind, .packages="data.table") %dopar% {
          
          # draw sample of precincts (cluster level)
          precincts_i <- sample(precincts, size = 5, replace = TRUE)
          # get observations
          bs_i <- lapply(precincts_i, function(x) stopdata[stopdata$policePrecinct==x,])
          bs_i <- rbindlist(bs_i)
          
          # estimate model and record coefficients
          coef(lm(model, bs_i))[1:2] # ignore FE-coefficients
      
     }


# be a good citizen and stop the snow clusters
stopCluster(cl = ctemp)


```

## Case study: Parallel processing

As a last step, we compute again $SE_{boot}$.

```{r message=FALSE, warning=FALSE}
se_boot <- apply(boot_coefs, 
                 MARGIN = 2,
                 FUN = sd)
se_boot
```


# Case Study II: Efficient Fixed Effects Estimation

## Case Study II: Efficient Fixed Effects Estimation

- Partial replication of ["Friends in High Places"](https://www.aeaweb.org/articles?id=10.1257/pol.6.3.63) by @cohen_malloy.
- Do US Senators with personal school ties help each other out in critical votes? 
- Data: [http://doi.org/10.3886/E114873V1](http://doi.org/10.3886/E114873V1). 
- Bottleneck: model matrix dimensions in fixed effects estimation.

## Data import and preparation

The data (and code) is provided in STATA format. We can import the main data set with the `foreign` package.

```{r message=FALSE, warning=FALSE}
# SET UP ------------------


# load packages
library(foreign)
library(data.table)
library(lmtest)

# fix vars
DATA_PATH <- "../data/data_for_tables.dta"

# import data
cm <- as.data.table(read.dta(DATA_PATH))
# keep only clean obs
cm <- cm[!(is.na(yes)|is.na(pctsumyessameparty)|is.na(pctsumyessameschool)|is.na(pctsumyessamestate))] 

```

## Main variables

- Dependent variable: indicator `yes` that is equal to 1 if the corresponding senator voted Yes on the given bill and 0 otherwise.
- Explanatory vars of interest:
  - `pctsumyessameschool` (the percentage of senators from the same school as the corresponding senator who voted Yes on the given bill)
  - `pctsumyessamestate` (the percentage of senators from the same state as the corresponding senator who voted Yes on the given bill)
  - `pctsumyessameparty` (the percentage of senators from the same party as the corresponding senator who voted Yes on the given bill) 

## Where is the bottleneck?

- Consider the two-way fixed effects specifications:
  - Senators (individual FE)
  - Congress (time FE) or Congress-Session-Vote (more granular time FE)
- The fixed effect specification means that we introduce an indicator variable (an intercept) for $N-1$ senators and $M-1$ congresses!

## Model matrix without FEs

The model matrix ($X$) without accounting for fixed effects has dimensions $425653\times4$: 

```{r message=FALSE, warning=FALSE}
# pooled model (no FE)
model0 <-   yes ~ 
  pctsumyessameschool + 
  pctsumyessamestate + 
  pctsumyessameparty 

dim(model.matrix(model0, data=cm))
```



## Model matrix with FE dummies

The model matrix of specification (1) is of dimensions $425653\times221$, and the model matrix of specification (2) even of $425653\times6929$:

```{r message=FALSE, warning=FALSE}
model1 <- 
  yes ~ pctsumyessameschool + pctsumyessamestate + pctsumyessameparty + 
  factor(congress) + factor(id) -1
mm1 <- model.matrix(model1, data=cm)
dim(mm1)

```

## OLS with large model matrices?

- Computation of a very large matrix inversion (because $\hat{\beta}_{OLS} = (\mathbf{X}^\intercal\mathbf{X})^{-1}\mathbf{X}^{\intercal}\mathbf{y}$)!
- And: the model matrix of specification 2 is about 22GB!


## Standard OLS with FE-dummies

In order to set a point of reference, we first estimate specification (1) with standard OLS.


```{r message=FALSE, warning=FALSE}

# fit specification (1)
runtime <- bench::mark(fit1 <- lm(data = cm, formula = model1))
coeftest(fit1)[2:4,]
# median amount of time needed for estimation
runtime$median
```


## Alternative: within estimator


- "Sweeping out the fixed effects dummies". 
- Preparatory step: "within transformation" or "demeaning" and is quite simple to implement. 
  - For each of the categories in the fixed effect variable the mean of the covariate and subtract the mean from the covariate's value.


## Alternative: within estimator

```{r message=FALSE, warning=FALSE}
# illustration of within transformation for the senator fixed effects
cm_within <- 
  with(cm, data.table(yes = yes - ave(yes, id),
                      pctsumyessameschool = pctsumyessameschool - ave(pctsumyessameschool, id),
                      pctsumyessamestate = pctsumyessamestate - ave(pctsumyessamestate, id),
                      pctsumyessameparty = pctsumyessameparty - ave(pctsumyessameparty, id)
                      ))

# comparison of dummy fixed effects estimator and within estimator
dummy_time <- bench::mark(fit_dummy <- 
              lm(yes ~ pctsumyessameschool + 
                           pctsumyessamestate + pctsumyessameparty + factor(id) -1, data = cm
                         ))
within_time <- bench::mark(fit_within <- 
                             lm(yes ~ pctsumyessameschool + 
                           pctsumyessamestate + pctsumyessameparty -1, data = cm_within))
```

## Comparison of dummies vs within transformation

```{r message=FALSE, warning=FALSE}

# computation time comparison
as.numeric(within_time$median)/as.numeric(dummy_time$median)

# comparison of estimates
coeftest(fit_dummy)[1:3, 1:3]
coeftest(fit_within)[, 1:3]

```

## Two-way FEs and within transformation?

- @GAURE20138 provides a generalization of the linear within-estimator to several fixed effects variables. 
- Implemented in the `lfe` package (@gaure_2013). 

## FE-estimation via `lfe`

```{r warning=FALSE, message=FALSE}
library(lfe)

# model and clustered SE specifications
model1 <- yes ~ pctsumyessameschool + pctsumyessamestate + pctsumyessameparty |congress+id|0|id
model2 <- yes ~ pctsumyessameschool + pctsumyessamestate + pctsumyessameparty |congress_session_votenumber+id|0|id

# estimation
fit1 <- felm(model1, data=cm)
fit2 <- felm(model2, data=cm)
```

## Regression Table

Replication of @cohen_malloy, Table 3, specifications (1) and (2)

```{r warning=FALSE, message=FALSE}
stargazer::stargazer(fit1,fit2,
                     type="text",
                     dep.var.labels = "Vote (yes/no)",
                     covariate.labels = c("School Connected Votes",
                                          "State Votes",
                                          "Party Votes"),
                     keep.stat = c("adj.rsq", "n"))
```




## References {.smaller}

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>


